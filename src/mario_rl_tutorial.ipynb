{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Train a Mario-playing RL Agent\n",
        "\n",
        "**Authors:** [Yuansong Feng](https://github.com/YuansongFeng)_, [Suraj Subramanian](https://github.com/suraj813)_, [Howard Wang](https://github.com/hw26)_, [Steven Guo](https://github.com/GuoYuzhang)_.\n",
        "\n",
        "\n",
        "This tutorial walks you through the fundamentals of Deep Reinforcement\n",
        "Learning. At the end, you will implement an AI-powered Mario (using\n",
        "[Double Deep Q-Networks](https://arxiv.org/pdf/1509.06461.pdf)_) that\n",
        "can play the game by itself.\n",
        "\n",
        "Although no prior knowledge of RL is necessary for this tutorial, you\n",
        "can familiarize yourself with these RL\n",
        "[concepts](https://spinningup.openai.com/en/latest/spinningup/rl_intro.html)_,\n",
        "and have this handy\n",
        "[cheatsheet](https://colab.research.google.com/drive/1eN33dPVtdPViiS1njTW_-r-IYCDTFU7N)_\n",
        "as your companion. The full code is available\n",
        "[here](https://github.com/yuansongFeng/MadMario/)_.\n",
        "\n",
        ".. figure:: /_static/img/mario.gif\n",
        "   :alt: mario\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "%%bash\n",
        "pip install gym-super-mario-bros==7.4.0\n",
        "pip install tensordict==0.3.0\n",
        "pip install torchrl==0.3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms as T\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from collections import deque\n",
        "import random, datetime, os\n",
        "\n",
        "# Gym is an OpenAI toolkit for RL\n",
        "import gym\n",
        "from gym.spaces import Box\n",
        "from gym.wrappers import FrameStack\n",
        "\n",
        "# NES Emulator for OpenAI Gym\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "\n",
        "# Super Mario environment for OpenAI Gym\n",
        "import gym_super_mario_bros\n",
        "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
        "\n",
        "from tensordict import TensorDict\n",
        "from torchrl.data import TensorDictReplayBuffer, LazyMemmapStorage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RL Definitions\n",
        "\n",
        "**Environment** The world that an agent interacts with and learns from.\n",
        "\n",
        "**Action** $a$ : How the Agent responds to the Environment. The\n",
        "set of all possible Actions is called *action-space*.\n",
        "\n",
        "**State** $s$ : The current characteristic of the Environment. The\n",
        "set of all possible States the Environment can be in is called\n",
        "*state-space*.\n",
        "\n",
        "**Reward** $r$ : Reward is the key feedback from Environment to\n",
        "Agent. It is what drives the Agent to learn and to change its future\n",
        "action. An aggregation of rewards over multiple time steps is called\n",
        "**Return**.\n",
        "\n",
        "**Optimal Action-Value function** $Q^*(s,a)$ : Gives the expected\n",
        "return if you start in state $s$, take an arbitrary action\n",
        "$a$, and then for each future time step take the action that\n",
        "maximizes returns. $Q$ can be said to stand for the “quality” of\n",
        "the action in a state. We try to approximate this function.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment\n",
        "\n",
        "### Initialize Environment\n",
        "\n",
        "In Mario, the environment consists of tubes, mushrooms and other\n",
        "components.\n",
        "\n",
        "When Mario makes an action, the environment responds with the changed\n",
        "(next) state, reward and other info.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(240, 256, 3),\n",
            " 0.0,\n",
            " False,\n",
            " {'coins': 0, 'flag_get': False, 'life': 2, 'score': 0, 'stage': 1, 'status': 'small', 'time': 400, 'world': 1, 'x_pos': 40, 'x_pos_screen': 40, 'y_pos': 79}\n"
          ]
        }
      ],
      "source": [
        "# Initialize Super Mario environment \n",
        "# (in v0.26 change render mode to 'human' to see results on the screen)\n",
        "if gym.__version__ < '0.26':\n",
        "    # For Gym versions earlier than 0.26, create the environment without specifying render mode\n",
        "    env = gym_super_mario_bros.make(\"SuperMarioBros2-v1\")\n",
        "else:\n",
        "    # For Gym versions 0.26 and later, create the environment with render mode set to 'rgb' and apply API compatibility\n",
        "    env = gym_super_mario_bros.make(\"SuperMarioBros2-v1\", render_mode='rgb', apply_api_compatibility=True)\n",
        "\n",
        "# actions for very simple movement\n",
        "# SIMPLE_MOVEMENT = [\n",
        "#     ['NOOP'],\n",
        "#     ['right'],\n",
        "#     ['right', 'A'],\n",
        "#     ['right', 'B'],\n",
        "#     ['right', 'A', 'B'],\n",
        "#     ['A'],\n",
        "#     ['left'],\n",
        "# ]\n",
        "\n",
        "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
        "\n",
        "# Reset the environment and get the initial state\n",
        "state = env.reset()\n",
        "\n",
        "# Perform an action (walking right) in the environment\n",
        "next_state, reward, done, info = env.step(action=0)\n",
        "\n",
        "# Print the resulting state shape, reward, termination status, and additional information\n",
        "print(f\"{next_state.shape},\\n {reward},\\n {done},\\n {info}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocess Environment\n",
        "\n",
        "Environment data is returned to the agent in ``next_state``. As you saw\n",
        "above, each state is represented by a ``[3, 240, 256]`` size array.\n",
        "Often that is more information than our agent needs; for instance,\n",
        "Mario’s actions do not depend on the color of the pipes or the sky!\n",
        "\n",
        "We use **Wrappers** to preprocess environment data before sending it to\n",
        "the agent.\n",
        "\n",
        "``GrayScaleObservation`` is a common wrapper to transform an RGB image\n",
        "to grayscale; doing so reduces the size of the state representation\n",
        "without losing useful information. Now the size of each state:\n",
        "``[1, 240, 256]``\n",
        "\n",
        "``ResizeObservation`` downsamples each observation into a square image.\n",
        "New size: ``[1, 84, 84]``\n",
        "\n",
        "``SkipFrame`` is a custom wrapper that inherits from ``gym.Wrapper`` and\n",
        "implements the ``step()`` function. Because consecutive frames don’t\n",
        "vary much, we can skip n-intermediate frames without losing much\n",
        "information. The n-th frame aggregates rewards accumulated over each\n",
        "skipped frame.\n",
        "\n",
        "``FrameStack`` is a wrapper that allows us to squash consecutive frames\n",
        "of the environment into a single observation point to feed to our\n",
        "learning model. This way, we can identify if Mario was landing or\n",
        "jumping based on the direction of his movement in the previous several\n",
        "frames.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class SkipFrame(gym.Wrapper):\n",
        "    def __init__(self, env, skip):\n",
        "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
        "        super().__init__(env)\n",
        "        self._skip = skip\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Repeat action, and sum reward\"\"\"\n",
        "        total_reward = 0.0\n",
        "        for i in range(self._skip):\n",
        "            # Accumulate reward and repeat the same action\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        return obs, total_reward, done, info\n",
        "\n",
        "\n",
        "class GrayScaleObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        obs_shape = self.observation_space.shape[:2]\n",
        "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
        "\n",
        "    def permute_orientation(self, observation):\n",
        "        # permute [H, W, C] array to [C, H, W] tensor\n",
        "        observation = np.transpose(observation, (2, 0, 1))\n",
        "        observation = torch.tensor(observation.copy(), dtype=torch.float)\n",
        "        return observation\n",
        "\n",
        "    def observation(self, observation):\n",
        "        observation = self.permute_orientation(observation)\n",
        "        transform = T.Grayscale()\n",
        "        observation = transform(observation)\n",
        "        return observation\n",
        "\n",
        "\n",
        "class ResizeObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env, shape):\n",
        "        super().__init__(env)\n",
        "        if isinstance(shape, int):\n",
        "            self.shape = (shape, shape)\n",
        "        else:\n",
        "            self.shape = tuple(shape)\n",
        "\n",
        "        obs_shape = self.shape + self.observation_space.shape[2:]\n",
        "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        transforms = T.Compose(\n",
        "            [T.Resize(self.shape, antialias=True), T.Normalize(0, 255)]\n",
        "        )\n",
        "        observation = transforms(observation).squeeze(0)\n",
        "        return observation\n",
        "\n",
        "\n",
        "# Apply Wrappers to environment\n",
        "env = SkipFrame(env, skip=4)\n",
        "env = GrayScaleObservation(env)\n",
        "env = ResizeObservation(env, shape=84)\n",
        "env = FrameStack(env, num_stack=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After applying the above wrappers to the environment, the final wrapped\n",
        "state consists of 4 gray-scaled consecutive frames stacked together, as\n",
        "shown above in the image on the left. Each time Mario makes an action,\n",
        "the environment responds with a state of this structure. The structure\n",
        "is represented by a 3-D array of size ``[4, 84, 84]``.\n",
        "\n",
        ".. figure:: /_static/img/mario_env.png\n",
        "   :alt: picture\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agent\n",
        "\n",
        "We create a class ``Mario`` to represent our agent in the game. Mario\n",
        "should be able to:\n",
        "\n",
        "-  **Act** according to the optimal action policy based on the current\n",
        "   state (of the environment).\n",
        "\n",
        "-  **Remember** experiences. Experience = (current state, current\n",
        "   action, reward, next state). Mario *caches* and later *recalls* his\n",
        "   experiences to update his action policy.\n",
        "\n",
        "-  **Learn** a better action policy over time\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Mario:\n",
        "    def __init__():\n",
        "        pass\n",
        "\n",
        "    def act(self, state):\n",
        "        \"\"\"Given a state, choose an epsilon-greedy action\"\"\"\n",
        "        pass\n",
        "\n",
        "    def cache(self, experience):\n",
        "        \"\"\"Add the experience to memory\"\"\"\n",
        "        pass\n",
        "\n",
        "    def recall(self):\n",
        "        \"\"\"Sample experiences from memory\"\"\"\n",
        "        pass\n",
        "\n",
        "    def learn(self):\n",
        "        \"\"\"Update online action value (Q) function with a batch of experiences\"\"\"\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the following sections, we will populate Mario’s parameters and\n",
        "define his functions.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Act\n",
        "\n",
        "For any given state, an agent can choose to do the most optimal action\n",
        "(**exploit**) or a random action (**explore**).\n",
        "\n",
        "Mario randomly explores with a chance of ``self.exploration_rate``; when\n",
        "he chooses to exploit, he relies on ``MarioNet`` (implemented in\n",
        "``Learn`` section) to provide the most optimal action.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Mario:\n",
        "    def __init__(self, state_dim, action_dim, save_dir):\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.save_dir = save_dir\n",
        "\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        print (f\"Device: {self.device}\")\n",
        "        \n",
        "        # Mario's DNN to predict the most optimal action - we implement this in the Learn section\n",
        "        self.net = MarioNet(self.state_dim, self.action_dim).float()\n",
        "        self.net = self.net.to(device=self.device)\n",
        "\n",
        "        self.exploration_rate = 1\n",
        "        self.exploration_rate_decay = 0.99999975\n",
        "        self.exploration_rate_min = 0.1\n",
        "        self.curr_step = 0\n",
        "\n",
        "        self.save_every = 5e5  # no. of experiences between saving Mario Net\n",
        "\n",
        "    def act(self, state):\n",
        "        \"\"\"\n",
        "    Given a state, choose an epsilon-greedy action and update value of step.\n",
        "\n",
        "    Inputs:\n",
        "    state(``LazyFrame``): A single observation of the current state, dimension is (state_dim)\n",
        "    Outputs:\n",
        "    ``action_idx`` (``int``): An integer representing which action Mario will perform\n",
        "    \"\"\"\n",
        "        # EXPLORE\n",
        "        if np.random.rand() < self.exploration_rate:\n",
        "            action_idx = np.random.randint(self.action_dim)\n",
        "\n",
        "        # EXPLOIT\n",
        "        else:\n",
        "            state = state[0].__array__() if isinstance(state, tuple) else state.__array__()\n",
        "            state = torch.tensor(state, device=self.device).unsqueeze(0)\n",
        "            action_values = self.net(state, model=\"online\")\n",
        "            action_idx = torch.argmax(action_values, axis=1).item()\n",
        "\n",
        "        # decrease exploration_rate\n",
        "        self.exploration_rate *= self.exploration_rate_decay\n",
        "        self.exploration_rate = max(self.exploration_rate_min, self.exploration_rate)\n",
        "\n",
        "        # increment step\n",
        "        self.curr_step += 1\n",
        "        return action_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cache and Recall\n",
        "\n",
        "These two functions serve as Mario’s “memory” process.\n",
        "\n",
        "``cache()``: Each time Mario performs an action, he stores the\n",
        "``experience`` to his memory. His experience includes the current\n",
        "*state*, *action* performed, *reward* from the action, the *next state*,\n",
        "and whether the game is *done*.\n",
        "\n",
        "``recall()``: Mario randomly samples a batch of experiences from his\n",
        "memory, and uses that to learn the game.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Mario(Mario):  # subclassing for continuity\n",
        "    def __init__(self, state_dim, action_dim, save_dir):\n",
        "        super().__init__(state_dim, action_dim, save_dir)\n",
        "        self.memory = TensorDictReplayBuffer(storage=LazyMemmapStorage(100000, device=torch.device(\"cpu\")))\n",
        "        self.batch_size = 32\n",
        "\n",
        "    def cache(self, state, next_state, action, reward, done):\n",
        "        \"\"\"\n",
        "        Store the experience to self.memory (replay buffer)\n",
        "\n",
        "        Inputs:\n",
        "        state (``LazyFrame``),\n",
        "        next_state (``LazyFrame``),\n",
        "        action (``int``),\n",
        "        reward (``float``),\n",
        "        done(``bool``))\n",
        "        \"\"\"\n",
        "        def first_if_tuple(x):\n",
        "            return x[0] if isinstance(x, tuple) else x\n",
        "        state = first_if_tuple(state).__array__()\n",
        "        next_state = first_if_tuple(next_state).__array__()\n",
        "\n",
        "        state = torch.tensor(state)\n",
        "        next_state = torch.tensor(next_state)\n",
        "        action = torch.tensor([action])\n",
        "        reward = torch.tensor([reward])\n",
        "        done = torch.tensor([done])\n",
        "\n",
        "        # self.memory.append((state, next_state, action, reward, done,))\n",
        "        self.memory.add(TensorDict({\"state\": state, \"next_state\": next_state, \"action\": action, \"reward\": reward, \"done\": done}, batch_size=[]))\n",
        "\n",
        "    def recall(self):\n",
        "        \"\"\"\n",
        "        Retrieve a batch of experiences from memory\n",
        "        \"\"\"\n",
        "        batch = self.memory.sample(self.batch_size).to(self.device)\n",
        "        state, next_state, action, reward, done = (batch.get(key) for key in (\"state\", \"next_state\", \"action\", \"reward\", \"done\"))\n",
        "        return state, next_state, action.squeeze(), reward.squeeze(), done.squeeze()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Learn\n",
        "\n",
        "Mario uses the [DDQN algorithm](https://arxiv.org/pdf/1509.06461)_\n",
        "under the hood. DDQN uses two ConvNets - $Q_{online}$ and\n",
        "$Q_{target}$ - that independently approximate the optimal\n",
        "action-value function.\n",
        "\n",
        "In our implementation, we share feature generator ``features`` across\n",
        "$Q_{online}$ and $Q_{target}$, but maintain separate FC\n",
        "classifiers for each. $\\theta_{target}$ (the parameters of\n",
        "$Q_{target}$) is frozen to prevent updating by backprop. Instead,\n",
        "it is periodically synced with $\\theta_{online}$ (more on this\n",
        "later).\n",
        "\n",
        "#### Neural Network\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class MarioNet(nn.Module):\n",
        "    \"\"\"mini CNN structure\n",
        "  input -> (conv2d + relu) x 3 -> flatten -> (dense + relu) x 2 -> output\n",
        "  \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        c, h, w = input_dim\n",
        "\n",
        "        if h != 84:\n",
        "            raise ValueError(f\"Expecting input height: 84, got: {h}\")\n",
        "        if w != 84:\n",
        "            raise ValueError(f\"Expecting input width: 84, got: {w}\")\n",
        "\n",
        "        self.online = self.__build_cnn(c, output_dim)\n",
        "\n",
        "        self.target = self.__build_cnn(c, output_dim)\n",
        "        self.target.load_state_dict(self.online.state_dict())\n",
        "\n",
        "        # Q_target parameters are frozen.\n",
        "        for p in self.target.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "    def forward(self, input, model):\n",
        "        if model == \"online\":\n",
        "            return self.online(input)\n",
        "        elif model == \"target\":\n",
        "            return self.target(input)\n",
        "\n",
        "    def __build_cnn(self, c, output_dim):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels=c, out_channels=32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3136, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, output_dim),\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### TD Estimate & TD Target\n",
        "\n",
        "Two values are involved in learning:\n",
        "\n",
        "**TD Estimate** - the predicted optimal $Q^*$ for a given state\n",
        "$s$\n",
        "\n",
        "\\begin{align}{TD}_e = Q_{online}^*(s,a)\\end{align}\n",
        "\n",
        "**TD Target** - aggregation of current reward and the estimated\n",
        "$Q^*$ in the next state $s'$\n",
        "\n",
        "\\begin{align}a' = argmax_{a} Q_{online}(s', a)\\end{align}\n",
        "\n",
        "\\begin{align}{TD}_t = r + \\gamma Q_{target}^*(s',a')\\end{align}\n",
        "\n",
        "Because we don’t know what next action $a'$ will be, we use the\n",
        "action $a'$ maximizes $Q_{online}$ in the next state\n",
        "$s'$.\n",
        "\n",
        "Notice we use the\n",
        "[@torch.no_grad()](https://pytorch.org/docs/stable/generated/torch.no_grad.html#no-grad)_\n",
        "decorator on ``td_target()`` to disable gradient calculations here\n",
        "(because we don’t need to backpropagate on $\\theta_{target}$).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Mario(Mario):\n",
        "    def __init__(self, state_dim, action_dim, save_dir):\n",
        "        super().__init__(state_dim, action_dim, save_dir)\n",
        "        self.gamma = 0.9\n",
        "\n",
        "    def td_estimate(self, state, action):\n",
        "        current_Q = self.net(state, model=\"online\")[\n",
        "            np.arange(0, self.batch_size), action\n",
        "        ]  # Q_online(s,a)\n",
        "        return current_Q\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def td_target(self, reward, next_state, done):\n",
        "        next_state_Q = self.net(next_state, model=\"online\")\n",
        "        best_action = torch.argmax(next_state_Q, axis=1)\n",
        "        next_Q = self.net(next_state, model=\"target\")[\n",
        "            np.arange(0, self.batch_size), best_action\n",
        "        ]\n",
        "        return (reward + (1 - done.float()) * self.gamma * next_Q).float()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Updating the model\n",
        "\n",
        "As Mario samples inputs from his replay buffer, we compute $TD_t$\n",
        "and $TD_e$ and backpropagate this loss down $Q_{online}$ to\n",
        "update its parameters $\\theta_{online}$ ($\\alpha$ is the\n",
        "learning rate ``lr`` passed to the ``optimizer``)\n",
        "\n",
        "\\begin{align}\\theta_{online} \\leftarrow \\theta_{online} + \\alpha \\nabla(TD_e - TD_t)\\end{align}\n",
        "\n",
        "$\\theta_{target}$ does not update through backpropagation.\n",
        "Instead, we periodically copy $\\theta_{online}$ to\n",
        "$\\theta_{target}$\n",
        "\n",
        "\\begin{align}\\theta_{target} \\leftarrow \\theta_{online}\\end{align}\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Mario(Mario):\n",
        "    def __init__(self, state_dim, action_dim, save_dir):\n",
        "        super().__init__(state_dim, action_dim, save_dir)\n",
        "        self.optimizer = torch.optim.Adam(self.net.parameters(), lr=0.00025)\n",
        "        self.loss_fn = torch.nn.SmoothL1Loss()\n",
        "\n",
        "    def update_Q_online(self, td_estimate, td_target):\n",
        "        loss = self.loss_fn(td_estimate, td_target)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        return loss.item()\n",
        "\n",
        "    def sync_Q_target(self):\n",
        "        self.net.target.load_state_dict(self.net.online.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save checkpoint\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Mario(Mario):\n",
        "    def save(self):\n",
        "        save_path = (\n",
        "            self.save_dir / f\"mario_net_{int(self.curr_step // self.save_every)}.chkpt\"\n",
        "        )\n",
        "        torch.save(\n",
        "            dict(model=self.net.state_dict(), exploration_rate=self.exploration_rate),\n",
        "            save_path,\n",
        "        )\n",
        "        print(f\"MarioNet saved to {save_path} at step {self.curr_step}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Putting it all together\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Mario(Mario):\n",
        "    def __init__(self, state_dim, action_dim, save_dir):\n",
        "        super().__init__(state_dim, action_dim, save_dir)\n",
        "        self.burnin = 1e4  # min. experiences before training\n",
        "        self.learn_every = 3  # no. of experiences between updates to Q_online\n",
        "        self.sync_every = 1e4  # no. of experiences between Q_target & Q_online sync\n",
        "\n",
        "    def learn(self):\n",
        "        if self.curr_step % self.sync_every == 0:\n",
        "            self.sync_Q_target()\n",
        "\n",
        "        if self.curr_step % self.save_every == 0:\n",
        "            self.save()\n",
        "\n",
        "        if self.curr_step < self.burnin:\n",
        "            return None, None\n",
        "\n",
        "        if self.curr_step % self.learn_every != 0:\n",
        "            return None, None\n",
        "\n",
        "        # Sample from memory\n",
        "        state, next_state, action, reward, done = self.recall()\n",
        "\n",
        "        # Get TD Estimate\n",
        "        td_est = self.td_estimate(state, action)\n",
        "\n",
        "        # Get TD Target\n",
        "        td_tgt = self.td_target(reward, next_state, done)\n",
        "\n",
        "        # Backpropagate loss through Q_online\n",
        "        loss = self.update_Q_online(td_est, td_tgt)\n",
        "\n",
        "        return (td_est.mean().item(), loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Logging\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time, datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class MetricLogger:\n",
        "    def __init__(self, save_dir):\n",
        "        self.save_log = save_dir / \"log\"\n",
        "        with open(self.save_log, \"w\") as f:\n",
        "            f.write(\n",
        "                f\"{'Episode':>8}{'Step':>8}{'Epsilon':>10}{'MeanReward':>15}\"\n",
        "                f\"{'MeanLength':>15}{'MeanLoss':>15}{'MeanQValue':>15}\"\n",
        "                f\"{'TimeDelta':>15}{'Time':>20}\\n\"\n",
        "            )\n",
        "        self.ep_rewards_plot = save_dir / \"reward_plot.jpg\"\n",
        "        self.ep_lengths_plot = save_dir / \"length_plot.jpg\"\n",
        "        self.ep_avg_losses_plot = save_dir / \"loss_plot.jpg\"\n",
        "        self.ep_avg_qs_plot = save_dir / \"q_plot.jpg\"\n",
        "\n",
        "        # History metrics\n",
        "        self.ep_rewards = []\n",
        "        self.ep_lengths = []\n",
        "        self.ep_avg_losses = []\n",
        "        self.ep_avg_qs = []\n",
        "\n",
        "        # Moving averages, added for every call to record()\n",
        "        self.moving_avg_ep_rewards = []\n",
        "        self.moving_avg_ep_lengths = []\n",
        "        self.moving_avg_ep_avg_losses = []\n",
        "        self.moving_avg_ep_avg_qs = []\n",
        "\n",
        "        # Current episode metric\n",
        "        self.init_episode()\n",
        "\n",
        "        # Timing\n",
        "        self.record_time = time.time()\n",
        "\n",
        "    def log_step(self, reward, loss, q):\n",
        "        self.curr_ep_reward += reward\n",
        "        self.curr_ep_length += 1\n",
        "        if loss:\n",
        "            self.curr_ep_loss += loss\n",
        "            self.curr_ep_q += q\n",
        "            self.curr_ep_loss_length += 1\n",
        "\n",
        "    def log_episode(self):\n",
        "        \"Mark end of episode\"\n",
        "        self.ep_rewards.append(self.curr_ep_reward)\n",
        "        self.ep_lengths.append(self.curr_ep_length)\n",
        "        if self.curr_ep_loss_length == 0:\n",
        "            ep_avg_loss = 0\n",
        "            ep_avg_q = 0\n",
        "        else:\n",
        "            ep_avg_loss = np.round(self.curr_ep_loss / self.curr_ep_loss_length, 5)\n",
        "            ep_avg_q = np.round(self.curr_ep_q / self.curr_ep_loss_length, 5)\n",
        "        self.ep_avg_losses.append(ep_avg_loss)\n",
        "        self.ep_avg_qs.append(ep_avg_q)\n",
        "\n",
        "        self.init_episode()\n",
        "\n",
        "    def init_episode(self):\n",
        "        self.curr_ep_reward = 0.0\n",
        "        self.curr_ep_length = 0\n",
        "        self.curr_ep_loss = 0.0\n",
        "        self.curr_ep_q = 0.0\n",
        "        self.curr_ep_loss_length = 0\n",
        "\n",
        "    def record(self, episode, epsilon, step):\n",
        "        mean_ep_reward = np.round(np.mean(self.ep_rewards[-100:]), 3)\n",
        "        mean_ep_length = np.round(np.mean(self.ep_lengths[-100:]), 3)\n",
        "        mean_ep_loss = np.round(np.mean(self.ep_avg_losses[-100:]), 3)\n",
        "        mean_ep_q = np.round(np.mean(self.ep_avg_qs[-100:]), 3)\n",
        "        self.moving_avg_ep_rewards.append(mean_ep_reward)\n",
        "        self.moving_avg_ep_lengths.append(mean_ep_length)\n",
        "        self.moving_avg_ep_avg_losses.append(mean_ep_loss)\n",
        "        self.moving_avg_ep_avg_qs.append(mean_ep_q)\n",
        "\n",
        "        last_record_time = self.record_time\n",
        "        self.record_time = time.time()\n",
        "        time_since_last_record = np.round(self.record_time - last_record_time, 3)\n",
        "\n",
        "        print(\n",
        "            f\"Episode {episode} - \"\n",
        "            f\"Step {step} - \"\n",
        "            f\"Epsilon {epsilon} - \"\n",
        "            f\"Mean Reward {mean_ep_reward} - \"\n",
        "            f\"Mean Length {mean_ep_length} - \"\n",
        "            f\"Mean Loss {mean_ep_loss} - \"\n",
        "            f\"Mean Q Value {mean_ep_q} - \"\n",
        "            f\"Time Delta {time_since_last_record} - \"\n",
        "            f\"Time {datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')}\"\n",
        "        )\n",
        "\n",
        "        with open(self.save_log, \"a\") as f:\n",
        "            f.write(\n",
        "                f\"{episode:8d}{step:8d}{epsilon:10.3f}\"\n",
        "                f\"{mean_ep_reward:15.3f}{mean_ep_length:15.3f}{mean_ep_loss:15.3f}{mean_ep_q:15.3f}\"\n",
        "                f\"{time_since_last_record:15.3f}\"\n",
        "                f\"{datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S'):>20}\\n\"\n",
        "            )\n",
        "\n",
        "        for metric in [\"ep_lengths\", \"ep_avg_losses\", \"ep_avg_qs\", \"ep_rewards\"]:\n",
        "            plt.clf()\n",
        "            plt.plot(getattr(self, f\"moving_avg_{metric}\"), label=f\"moving_avg_{metric}\")\n",
        "            plt.legend()\n",
        "            plt.savefig(getattr(self, f\"{metric}_plot\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Let’s play!\n",
        "\n",
        "In this example we run the training loop for 40 episodes, but for Mario to truly learn the ways of\n",
        "his world, we suggest running the loop for at least 40,000 episodes!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Checking if CUDA is available**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using CUDA: True\n",
            "\n"
          ]
        }
      ],
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "print(f\"Using CUDA: {use_cuda}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 0 - Step 739 - Epsilon 0.9998152670421141 - Mean Reward 1981.0 - Mean Length 739.0 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 7.448 - Time 2024-02-29T11:40:04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 20 - Step 22015 - Epsilon 0.994511367199336 - Mean Reward 1261.476 - Mean Length 1048.333 - Mean Loss 0.223 - Mean Q Value 0.727 - Time Delta 234.508 - Time 2024-02-29T11:43:59\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 40 - Step 51877 - Epsilon 0.9871144867220536 - Mean Reward 1305.366 - Mean Length 1265.293 - Mean Loss 0.373 - Mean Q Value 2.104 - Time Delta 365.563 - Time 2024-02-29T11:50:04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 60 - Step 83158 - Epsilon 0.9794251093096699 - Mean Reward 1288.689 - Mean Length 1363.246 - Mean Loss 0.472 - Mean Q Value 3.285 - Time Delta 422.335 - Time 2024-02-29T11:57:07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 80 - Step 108630 - Epsilon 0.9732079458934535 - Mean Reward 1266.988 - Mean Length 1341.111 - Mean Loss 0.545 - Mean Q Value 4.363 - Time Delta 359.232 - Time 2024-02-29T12:03:06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 100 - Step 137515 - Epsilon 0.966205480842705 - Mean Reward 1265.02 - Mean Length 1367.76 - Mean Loss 0.605 - Mean Q Value 5.258 - Time Delta 410.105 - Time 2024-02-29T12:09:56\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 120 - Step 164419 - Epsilon 0.9597285881754501 - Mean Reward 1278.6 - Mean Length 1424.04 - Mean Loss 0.72 - Mean Q Value 6.858 - Time Delta 381.853 - Time 2024-02-29T12:16:18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 140 - Step 196705 - Epsilon 0.9520133167042294 - Mean Reward 1297.87 - Mean Length 1448.28 - Mean Loss 0.777 - Mean Q Value 8.024 - Time Delta 459.816 - Time 2024-02-29T12:23:58\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 160 - Step 223173 - Epsilon 0.9457346397138492 - Mean Reward 1312.77 - Mean Length 1400.15 - Mean Loss 0.808 - Mean Q Value 8.917 - Time Delta 376.923 - Time 2024-02-29T12:30:14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 180 - Step 247521 - Epsilon 0.9399954372270106 - Mean Reward 1332.42 - Mean Length 1388.91 - Mean Loss 0.824 - Mean Q Value 9.556 - Time Delta 347.122 - Time 2024-02-29T12:36:02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 200 - Step 274652 - Epsilon 0.9336412561515389 - Mean Reward 1344.59 - Mean Length 1371.37 - Mean Loss 0.834 - Mean Q Value 10.117 - Time Delta 384.826 - Time 2024-02-29T12:42:26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 220 - Step 299639 - Epsilon 0.9278272102589356 - Mean Reward 1344.1 - Mean Length 1352.2 - Mean Loss 0.853 - Mean Q Value 10.753 - Time Delta 353.472 - Time 2024-02-29T12:48:20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 240 - Step 325649 - Epsilon 0.9218135860566143 - Mean Reward 1343.01 - Mean Length 1289.44 - Mean Loss 0.873 - Mean Q Value 11.396 - Time Delta 368.983 - Time 2024-02-29T12:54:29\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 260 - Step 357598 - Epsilon 0.9144801555321748 - Mean Reward 1367.71 - Mean Length 1344.25 - Mean Loss 0.881 - Mean Q Value 11.872 - Time Delta 451.625 - Time 2024-02-29T13:02:00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 280 - Step 382351 - Epsilon 0.9088385966953179 - Mean Reward 1379.26 - Mean Length 1348.3 - Mean Loss 0.886 - Mean Q Value 12.129 - Time Delta 350.065 - Time 2024-02-29T13:07:51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 300 - Step 411779 - Epsilon 0.9021768057514472 - Mean Reward 1373.45 - Mean Length 1371.27 - Mean Loss 0.88 - Mean Q Value 12.209 - Time Delta 417.37 - Time 2024-02-29T13:14:48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 320 - Step 445044 - Epsilon 0.8947051879378349 - Mean Reward 1438.13 - Mean Length 1454.05 - Mean Loss 0.868 - Mean Q Value 12.189 - Time Delta 473.021 - Time 2024-02-29T13:22:41\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 340 - Step 470102 - Epsilon 0.889117825876122 - Mean Reward 1456.05 - Mean Length 1444.53 - Mean Loss 0.856 - Mean Q Value 12.215 - Time Delta 357.228 - Time 2024-02-29T13:28:38\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 360 - Step 498344 - Epsilon 0.8828623181765163 - Mean Reward 1493.01 - Mean Length 1407.46 - Mean Loss 0.861 - Mean Q Value 12.357 - Time Delta 400.52 - Time 2024-02-29T13:35:19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MarioNet saved to checkpoints/2024-02-29T11-39-57/mario_net_1.chkpt at step 500000\n",
            "Episode 380 - Step 523910 - Epsilon 0.8772374976346495 - Mean Reward 1492.13 - Mean Length 1415.59 - Mean Loss 0.865 - Mean Q Value 12.669 - Time Delta 364.162 - Time 2024-02-29T13:41:23\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 400 - Step 541606 - Epsilon 0.8733651703641448 - Mean Reward 1481.28 - Mean Length 1298.27 - Mean Loss 0.876 - Mean Q Value 13.141 - Time Delta 250.27 - Time 2024-02-29T13:45:33\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 420 - Step 562709 - Epsilon 0.8687696465679853 - Mean Reward 1430.57 - Mean Length 1176.65 - Mean Loss 0.892 - Mean Q Value 13.763 - Time Delta 300.889 - Time 2024-02-29T13:50:34\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 440 - Step 583999 - Epsilon 0.8641579034356062 - Mean Reward 1392.25 - Mean Length 1138.97 - Mean Loss 0.91 - Mean Q Value 14.216 - Time Delta 303.699 - Time 2024-02-29T13:55:38\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 460 - Step 605674 - Epsilon 0.8594879113986515 - Mean Reward 1356.63 - Mean Length 1073.3 - Mean Loss 0.927 - Mean Q Value 14.569 - Time Delta 309.998 - Time 2024-02-29T14:00:48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 480 - Step 629276 - Epsilon 0.8544314348849887 - Mean Reward 1375.1 - Mean Length 1053.66 - Mean Loss 0.949 - Mean Q Value 14.984 - Time Delta 336.151 - Time 2024-02-29T14:06:24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 500 - Step 652808 - Epsilon 0.8494195709789697 - Mean Reward 1463.49 - Mean Length 1112.02 - Mean Loss 0.976 - Mean Q Value 15.456 - Time Delta 337.279 - Time 2024-02-29T14:12:01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 520 - Step 672916 - Epsilon 0.8451602530279864 - Mean Reward 1483.77 - Mean Length 1102.07 - Mean Loss 0.997 - Mean Q Value 15.679 - Time Delta 288.404 - Time 2024-02-29T14:16:50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 540 - Step 690105 - Epsilon 0.8415361800279467 - Mean Reward 1493.94 - Mean Length 1061.06 - Mean Loss 1.015 - Mean Q Value 15.937 - Time Delta 246.241 - Time 2024-02-29T14:20:56\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 560 - Step 707930 - Epsilon 0.8377944272424065 - Mean Reward 1485.45 - Mean Length 1022.56 - Mean Loss 1.031 - Mean Q Value 16.377 - Time Delta 253.843 - Time 2024-02-29T14:25:10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 580 - Step 725333 - Epsilon 0.8341573105129991 - Mean Reward 1485.01 - Mean Length 960.57 - Mean Loss 1.051 - Mean Q Value 16.828 - Time Delta 248.516 - Time 2024-02-29T14:29:18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 600 - Step 747112 - Epsilon 0.8296278739443571 - Mean Reward 1444.33 - Mean Length 943.04 - Mean Loss 1.059 - Mean Q Value 17.164 - Time Delta 312.188 - Time 2024-02-29T14:34:30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 620 - Step 763323 - Epsilon 0.8262724031931055 - Mean Reward 1442.94 - Mean Length 904.07 - Mean Loss 1.074 - Mean Q Value 17.637 - Time Delta 231.26 - Time 2024-02-29T14:38:22\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 640 - Step 783571 - Epsilon 0.8221003800651964 - Mean Reward 1481.53 - Mean Length 934.66 - Mean Loss 1.092 - Mean Q Value 18.273 - Time Delta 289.944 - Time 2024-02-29T14:43:12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 660 - Step 807004 - Epsilon 0.8172983892773451 - Mean Reward 1526.11 - Mean Length 990.74 - Mean Loss 1.095 - Mean Q Value 18.62 - Time Delta 335.911 - Time 2024-02-29T14:48:47\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 680 - Step 825836 - Epsilon 0.8134595916006349 - Mean Reward 1568.78 - Mean Length 1005.03 - Mean Loss 1.101 - Mean Q Value 18.883 - Time Delta 270.259 - Time 2024-02-29T14:53:18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 700 - Step 844742 - Epsilon 0.8096238463267683 - Mean Reward 1608.61 - Mean Length 976.3 - Mean Loss 1.119 - Mean Q Value 19.148 - Time Delta 271.111 - Time 2024-02-29T14:57:49\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 720 - Step 866011 - Epsilon 0.8053302984423434 - Mean Reward 1600.07 - Mean Length 1026.88 - Mean Loss 1.126 - Mean Q Value 19.37 - Time Delta 304.808 - Time 2024-02-29T15:02:54\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 740 - Step 881211 - Epsilon 0.8022758500534907 - Mean Reward 1561.26 - Mean Length 976.4 - Mean Loss 1.13 - Mean Q Value 19.332 - Time Delta 218.321 - Time 2024-02-29T15:06:32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 760 - Step 902370 - Epsilon 0.7980432155048989 - Mean Reward 1573.07 - Mean Length 953.66 - Mean Loss 1.146 - Mean Q Value 19.63 - Time Delta 302.163 - Time 2024-02-29T15:11:34\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 780 - Step 924909 - Epsilon 0.7935590862731916 - Mean Reward 1600.37 - Mean Length 990.73 - Mean Loss 1.15 - Mean Q Value 19.79 - Time Delta 322.724 - Time 2024-02-29T15:16:57\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 800 - Step 939071 - Epsilon 0.7907544578005221 - Mean Reward 1575.62 - Mean Length 943.29 - Mean Loss 1.143 - Mean Q Value 19.862 - Time Delta 203.464 - Time 2024-02-29T15:20:20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 820 - Step 958321 - Epsilon 0.7869580938251234 - Mean Reward 1651.79 - Mean Length 923.1 - Mean Loss 1.155 - Mean Q Value 20.102 - Time Delta 277.017 - Time 2024-02-29T15:24:57\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 840 - Step 975368 - Epsilon 0.783611411177686 - Mean Reward 1688.65 - Mean Length 941.57 - Mean Loss 1.169 - Mean Q Value 20.605 - Time Delta 244.683 - Time 2024-02-29T15:29:02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 860 - Step 993976 - Epsilon 0.7799745164138555 - Mean Reward 1636.81 - Mean Length 916.06 - Mean Loss 1.172 - Mean Q Value 20.77 - Time Delta 266.679 - Time 2024-02-29T15:33:29\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MarioNet saved to checkpoints/2024-02-29T11-39-57/mario_net_2.chkpt at step 1000000\n",
            "Episode 880 - Step 1009838 - Epsilon 0.7768876516090392 - Mean Reward 1543.64 - Mean Length 849.29 - Mean Loss 1.181 - Mean Q Value 21.154 - Time Delta 228.111 - Time 2024-02-29T15:37:17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 900 - Step 1027530 - Epsilon 0.7734590650056219 - Mean Reward 1518.03 - Mean Length 884.59 - Mean Loss 1.206 - Mean Q Value 21.702 - Time Delta 254.194 - Time 2024-02-29T15:41:31\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 920 - Step 1039536 - Epsilon 0.7711410078964139 - Mean Reward 1422.63 - Mean Length 812.15 - Mean Loss 1.217 - Mean Q Value 22.145 - Time Delta 173.433 - Time 2024-02-29T15:44:24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 940 - Step 1058274 - Epsilon 0.7675370453657684 - Mean Reward 1462.99 - Mean Length 829.06 - Mean Loss 1.231 - Mean Q Value 22.425 - Time Delta 269.41 - Time 2024-02-29T15:48:54\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 960 - Step 1074151 - Epsilon 0.764496536829132 - Mean Reward 1467.54 - Mean Length 801.75 - Mean Loss 1.248 - Mean Q Value 22.856 - Time Delta 228.846 - Time 2024-02-29T15:52:43\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 980 - Step 1091929 - Epsilon 0.7611062711456703 - Mean Reward 1530.99 - Mean Length 820.91 - Mean Loss 1.264 - Mean Q Value 23.246 - Time Delta 255.526 - Time 2024-02-29T15:56:58\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rinzler/github/Mario_RL/env/lib/python3.10/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 999 - Step 1104258 - Epsilon 0.7587639626928099 - Mean Reward 1561.75 - Mean Length 777.35 - Mean Loss 1.281 - Mean Q Value 23.599 - Time Delta 191.607 - Time 2024-02-29T16:00:10\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "save_dir = Path(\"checkpoints\") / datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
        "save_dir.mkdir(parents=True)\n",
        "\n",
        "mario = Mario(state_dim=(4, 84, 84), action_dim=env.action_space.n, save_dir=save_dir)\n",
        "\n",
        "logger = MetricLogger(save_dir)\n",
        "\n",
        "episodes = 1000\n",
        "for e in range(episodes):\n",
        "\n",
        "    state = env.reset()\n",
        "\n",
        "    # Play the game!\n",
        "    while True:\n",
        "\n",
        "        # Render the game frame\n",
        "        env.render()\n",
        "        \n",
        "        # Run agent on the state\n",
        "        action = mario.act(state)\n",
        "\n",
        "        # Agent performs action\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "\n",
        "        # Remember\n",
        "        mario.cache(state, next_state, action, reward, done)\n",
        "\n",
        "        # Learn\n",
        "        q, loss = mario.learn()\n",
        "\n",
        "        # Logging\n",
        "        logger.log_step(reward, loss, q)\n",
        "\n",
        "        # Update state\n",
        "        state = next_state\n",
        "\n",
        "        # Check if end of game\n",
        "        if done or info[\"flag_get\"]:\n",
        "            break\n",
        "\n",
        "    logger.log_episode()\n",
        "\n",
        "    if (e % 20 == 0) or (e == episodes - 1):\n",
        "        logger.record(episode=e, epsilon=mario.exploration_rate, step=mario.curr_step)\n",
        "        \n",
        "# Close the environment after training is done\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "In this tutorial, we saw how we can use PyTorch to train a game-playing AI. You can use the same methods\n",
        "to train an AI to play any of the games at the [OpenAI gym](https://gym.openai.com/)_. Hope you enjoyed this tutorial, feel free to reach us at\n",
        "[our github](https://github.com/yuansongFeng/MadMario/)_!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import gym\n",
        "# import torch\n",
        "# from nes_py.wrappers import JoypadSpace\n",
        "# from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
        "# from pathlib import Path\n",
        "# from my_mario_model import MarioNet  # Replace 'my_mario_model' with your model module\n",
        "\n",
        "# def load_model(checkpoint_path):\n",
        "#     model = MarioNet(input_dim=(4, 84, 84), output_dim=7)  # Adjust parameters as per your model\n",
        "#     checkpoint = torch.load(checkpoint_path)\n",
        "#     model.load_state_dict(checkpoint['model'])\n",
        "#     model.eval()\n",
        "#     return model\n",
        "\n",
        "# def play_mario(model, episodes=1):\n",
        "#     env = gym_super_mario_bros.make(\"SuperMarioBros-v1\")\n",
        "#     env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
        "\n",
        "#     for episode in range(episodes):\n",
        "#         state = env.reset()\n",
        "#         done = False\n",
        "#         total_reward = 0\n",
        "\n",
        "#         while not done:\n",
        "#             # Preprocess the state if necessary\n",
        "#             state = preprocess_state(state)\n",
        "\n",
        "#             # Convert state to tensor and unsqueeze to add batch dimension\n",
        "#             state = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "#             # Get action from the model\n",
        "#             with torch.no_grad():\n",
        "#                 action_values = model(state)\n",
        "#                 action = torch.argmax(action_values, dim=1).item()\n",
        "\n",
        "#             # Step the environment\n",
        "#             next_state, reward, done, _ = env.step(action)\n",
        "#             total_reward += reward\n",
        "#             state = next_state\n",
        "\n",
        "#         print(f\"Episode {episode + 1} completed with total reward: {total_reward}\")\n",
        "\n",
        "# def preprocess_state(state):\n",
        "#     # Implement any necessary preprocessing steps here (e.g., resize, grayscale, etc.)\n",
        "#     return state\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     checkpoint_path = Path(\"checkpoints\") / \"mario_net_1.chkpt\"  # Adjust path accordingly\n",
        "#     model = load_model(checkpoint_path)\n",
        "#     play_mario(model, episodes=5)  # Adjust number of episodes as needed\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
