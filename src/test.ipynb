{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stable_baselines3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DQN, A2C, PPO\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate_policy\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgym_super_mario_bros\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'stable_baselines3'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import gym\n",
    "import pickle\n",
    "import random\n",
    "from stable_baselines3 import DQN, A2C, PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import gym_super_mario_bros\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros.actions import RIGHT_ONLY\n",
    "from stable_baselines3.common import atari_wrappers\n",
    "import tensorflow as tf\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    # Set parameters for the experiment\n",
    "    environmentID = \"SuperMarioBros2-v1\"\n",
    "    trainMode = True  # Set to False if you wish to load a pre-trained model\n",
    "    learningAlg = \"PPO\"  # Choose between 'DQN', 'A2C', and 'PPO'\n",
    "    seed = random.randint(0, 1000) if trainMode else 42  # Set a seed number here\n",
    "    num_training_steps = 10000\n",
    "    num_test_episodes = 10\n",
    "    learning_rate = 0.00083\n",
    "    gamma = 0.995\n",
    "    policy_rendering = True\n",
    "\n",
    "    # Define a function to create the learning environment\n",
    "    def make_env(gym_id, seed):\n",
    "        env = gym_super_mario_bros.make(gym_id)\n",
    "        env = JoypadSpace(env, RIGHT_ONLY)\n",
    "        env = atari_wrappers.MaxAndSkipEnv(env, 4)\n",
    "        env = atari_wrappers.NoopResetEnv(env, noop_max=30)\n",
    "        env = atari_wrappers.ClipRewardEnv(env)\n",
    "        env.seed(seed)    \n",
    "        env.action_space.seed(seed)\n",
    "        env.observation_space.seed(seed)\n",
    "        return env\n",
    "\n",
    "    # Create the learning environment\n",
    "    environment = make_env(environmentID, seed)\n",
    "\n",
    "    # Initialize the agent's model\n",
    "    if learningAlg == \"DQN\":\n",
    "        model = DQN(\"CnnPolicy\", environment, seed=seed, learning_rate=learning_rate, gamma=gamma, buffer_size=50000, exploration_fraction=0.9, verbose=1)\n",
    "    elif learningAlg == \"A2C\":\n",
    "        model = A2C(\"CnnPolicy\", environment, seed=seed, learning_rate=learning_rate, gamma=gamma, verbose=1)\n",
    "    elif learningAlg == \"PPO\":\n",
    "        model = PPO(\"CnnPolicy\", environment, seed=seed, learning_rate=learning_rate, gamma=gamma, verbose=1)\n",
    "    else:\n",
    "        raise ValueError(f\"UNKNOWN learningAlg={learningAlg}\")\n",
    "\n",
    "    # Train the agent or load a pre-trained model\n",
    "    # Train the agent or load a pre-trained model\n",
    "    if trainMode:\n",
    "        model.learn(total_timesteps=num_training_steps)  # Removed progress_bar=True\n",
    "        policyFileName = f\"{learningAlg}-{environmentID}-seed{str(seed)}.policy.pkl\"\n",
    "        print(\"Saving policy \" + str(policyFileName))\n",
    "        model.save(policyFileName)\n",
    "    else:\n",
    "        policyFileName = input(\"Enter the name of the policy file to load: \")\n",
    "        print(\"Loading policy...\")\n",
    "        model = model.load(policyFileName)\n",
    "\n",
    "\n",
    "    # Evaluate and visualize the agent's performance\n",
    "    print(\"Evaluating policy...\")\n",
    "    mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=num_test_episodes * 5, render=policy_rendering)\n",
    "    print(f\"EVALUATION: mean_reward={mean_reward} std_reward={std_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable-baselines3==1.6.0 (from stable-baselines3[extra]==1.6.0)\n",
      "  Using cached stable_baselines3-1.6.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting gym==0.21 (from stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0)\n",
      "  Using cached gym-0.21.0.tar.gz (1.5 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[1 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m error in gym setup command: 'extras_require' must be a dictionary whose values are strings or lists of strings containing valid project/version requirement specifiers.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install stable-baselines3[extra]==1.6.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
