{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gym'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gym'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import gym\n",
    "import pickle\n",
    "import random\n",
    "from stable_baselines3 import DQN, A2C, PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import gym_super_mario_bros\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros.actions import RIGHT_ONLY\n",
    "from stable_baselines3.common import atari_wrappers\n",
    "import tensorflow as tf\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    # Set parameters for the experiment\n",
    "    environmentID = \"SuperMarioBros2-v1\"\n",
    "    trainMode = True  # Set to False if you wish to load a pre-trained model\n",
    "    learningAlg = \"PPO\"  # Choose between 'DQN', 'A2C', and 'PPO'\n",
    "    seed = random.randint(0, 1000) if trainMode else 42  # Set a seed number here\n",
    "    num_training_steps = 10000\n",
    "    num_test_episodes = 10\n",
    "    learning_rate = 0.00083\n",
    "    gamma = 0.995\n",
    "    policy_rendering = True\n",
    "\n",
    "    # Define a function to create the learning environment\n",
    "    def make_env(gym_id, seed):\n",
    "        env = gym_super_mario_bros.make(gym_id)\n",
    "        env = JoypadSpace(env, RIGHT_ONLY)\n",
    "        env = atari_wrappers.MaxAndSkipEnv(env, 4)\n",
    "        env = atari_wrappers.NoopResetEnv(env, noop_max=30)\n",
    "        env = atari_wrappers.ClipRewardEnv(env)\n",
    "        env.seed(seed)    \n",
    "        env.action_space.seed(seed)\n",
    "        env.observation_space.seed(seed)\n",
    "        return env\n",
    "\n",
    "    # Create the learning environment\n",
    "    environment = make_env(environmentID, seed)\n",
    "\n",
    "    # Initialize the agent's model\n",
    "    if learningAlg == \"DQN\":\n",
    "        model = DQN(\"CnnPolicy\", environment, seed=seed, learning_rate=learning_rate, gamma=gamma, buffer_size=50000, exploration_fraction=0.9, verbose=1)\n",
    "    elif learningAlg == \"A2C\":\n",
    "        model = A2C(\"CnnPolicy\", environment, seed=seed, learning_rate=learning_rate, gamma=gamma, verbose=1)\n",
    "    elif learningAlg == \"PPO\":\n",
    "        model = PPO(\"CnnPolicy\", environment, seed=seed, learning_rate=learning_rate, gamma=gamma, verbose=1)\n",
    "    else:\n",
    "        raise ValueError(f\"UNKNOWN learningAlg={learningAlg}\")\n",
    "\n",
    "    # Train the agent or load a pre-trained model\n",
    "    # Train the agent or load a pre-trained model\n",
    "    if trainMode:\n",
    "        model.learn(total_timesteps=num_training_steps)  # Removed progress_bar=True\n",
    "        policyFileName = f\"{learningAlg}-{environmentID}-seed{str(seed)}.policy.pkl\"\n",
    "        print(\"Saving policy \" + str(policyFileName))\n",
    "        model.save(policyFileName)\n",
    "    else:\n",
    "        policyFileName = input(\"Enter the name of the policy file to load: \")\n",
    "        print(\"Loading policy...\")\n",
    "        model = model.load(policyFileName)\n",
    "\n",
    "\n",
    "    # Evaluate and visualize the agent's performance\n",
    "    print(\"Evaluating policy...\")\n",
    "    mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=num_test_episodes * 5, render=policy_rendering)\n",
    "    print(f\"EVALUATION: mean_reward={mean_reward} std_reward={std_reward}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
